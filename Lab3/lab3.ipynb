{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lab 3\n",
    "### Jaydeep Dey - 20BCE1419"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 667,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from string import punctuation\n",
    "\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 668,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = [\n",
    "    \"Selenium is a portable framework for testing web applications\",\n",
    "    \"Beautiful Soup is useful for web scraping\",\n",
    "    \"It is a python package for parsing the pages\",\n",
    "    \"Java programming can be used for web applications\",\n",
    "    \"scraping web and crawling web is useful\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 669,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(word):\n",
    "    word = word.strip()\n",
    "    word = word.lower()\n",
    "    word = word_tokenize(word)\n",
    "    new_word = list()\n",
    "    for i in word:\n",
    "        if i not in stop_words and i not in punctuation:\n",
    "            new_word.append(i)\n",
    "    return new_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 670,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['selenium', 'portable', 'framework', 'testing', 'web', 'applications'],\n",
       " ['beautiful', 'soup', 'useful', 'web', 'scraping'],\n",
       " ['python', 'package', 'parsing', 'pages'],\n",
       " ['java', 'programming', 'used', 'web', 'applications'],\n",
       " ['scraping', 'web', 'crawling', 'web', 'useful']]"
      ]
     },
     "execution_count": 670,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_doc = list()\n",
    "\n",
    "for i in doc:\n",
    "    new_doc.append(preprocessing(i))\n",
    "new_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 671,
   "metadata": {},
   "outputs": [],
   "source": [
    "def WordOccurance(text, word):\n",
    "    new_text = text.replace('/[^A-Za-z0-9]/g', '').lower().strip().split()\n",
    "    word_pos = list()\n",
    "    word_count = 0\n",
    "    for i in range(len(new_text)):\n",
    "        if word == new_text[i]:\n",
    "            word_count += 1\n",
    "            word_pos.append(i)\n",
    "    return (word_count, word_pos)\n",
    "\n",
    "# WordOccurance(\"selenium portable selenium selenium portable portable\", 'portable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'selenium': [(1, 1, [0])],\n",
       " 'portable': [(1, 1, [3])],\n",
       " 'framework': [(1, 1, [4])],\n",
       " 'testing': [(1, 1, [6])],\n",
       " 'web': [(1, 1, [7])],\n",
       " 'applications': [(1, 1, [8])],\n",
       " 'beautiful': [(2, 1, [0])],\n",
       " 'soup': [(2, 1, [1])],\n",
       " 'useful': [(2, 1, [3])],\n",
       " 'scraping': [(2, 1, [6])],\n",
       " 'python': [(3, 1, [3])],\n",
       " 'package': [(3, 1, [4])],\n",
       " 'parsing': [(3, 1, [6])],\n",
       " 'pages': [(3, 1, [8])],\n",
       " 'java': [(4, 1, [0])],\n",
       " 'programming': [(4, 1, [1])],\n",
       " 'used': [(4, 1, [4])],\n",
       " 'crawling': [(5, 1, [3])]}"
      ]
     },
     "execution_count": 672,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverted_index = dict()\n",
    "\n",
    "for (i,text) in enumerate(doc):\n",
    "    words = preprocessing(text)\n",
    "    for word in words:\n",
    "        if word not in inverted_index.keys():\n",
    "            inverted_index[word] = []\n",
    "            wordcount, wordpos = WordOccurance(text, word)\n",
    "            inverted_index[word].append((i+1, wordcount, wordpos))\n",
    "inverted_index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search Word in Inverted Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selenium word occurs in the following position\n",
      "Word 'Selenium'\n",
      "Doc no  no.of times  offset number\n",
      "D 1 \t\t 1 \t [0]\n",
      "Word 'Web'\n",
      "Doc no  no.of times  offset number\n",
      "D 1 \t\t 1 \t [7]\n"
     ]
    }
   ],
   "source": [
    "print(\"Selenium word occurs in the following position\")\n",
    "print(\"Word 'Selenium'\")\n",
    "print(\"Doc no  no.of times  offset number\")\n",
    "for word in inverted_index.keys():\n",
    "    if word == \"Selenium\".lower():\n",
    "        data = inverted_index[word][0]\n",
    "        print('D',data[0], \"\\t\\t\", data[1],\"\\t\" ,data[2])\n",
    "\n",
    "print(\"Word 'Web'\")\n",
    "print(\"Doc no  no.of times  offset number\")\n",
    "for word in inverted_index.keys():\n",
    "    if word==\"web\".lower():\n",
    "        data = inverted_index[word][0]\n",
    "        print('D',data[0], \"\\t\\t\", data[1],\"\\t\" ,data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'soup'\n",
      "Doc no  no.of times  offset number\n",
      "2 \t\t 1 \t [1]\n"
     ]
    }
   ],
   "source": [
    "print(\"Word 'soup'\")\n",
    "print(\"Doc no  no.of times  offset number\")\n",
    "for word in inverted_index.keys():\n",
    "    if word==\"soup\".lower():\n",
    "        data = inverted_index[word][0]\n",
    "        print(data[0], \"\\t\\t\", data[1],\"\\t\" ,data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'Python' and 'Java' \n",
      "Doc no  no.of times  offset number\n",
      "D 3 \t\t 1 \t [3]\n",
      "D 4 \t\t 1 \t [0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Word 'Python' and 'Java' \")\n",
    "print(\"Doc no  no.of times  offset number\")\n",
    "for word in inverted_index.keys():\n",
    "    if word==\"python\".lower() or word==\"java\".lower() :\n",
    "        data = inverted_index[word][0]\n",
    "        print('D', data[0], \"\\t\\t\", data[1],\"\\t\" ,data[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 676,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 'Web and Craw'\n",
      "Doc no  no.of times  offset number\n"
     ]
    }
   ],
   "source": [
    "print(\"Word 'Web and Craw'\")\n",
    "print(\"Doc no  no.of times  offset number\")\n",
    "for word in inverted_index.keys():\n",
    "    if word==\"web\".lower() and word==\"craw\".lower():\n",
    "        data = inverted_index[word][0]\n",
    "        print('D', data[0], \"\\t\\t\", data[1],\"\\t\" ,data[2])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">PART  B</p> \n",
    "\n",
    "<p align=\"center\">Boolean and Vector Model, TF-IDF, Similarity Measures</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 677,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc1 = [\n",
    "    \"Information Retrieval Systems is used with database systems\",\n",
    "    \"Information is in Storage\",\n",
    "    \"Digital Speech can be used in Synthesis and Systems\",\n",
    "    \"Speech Filtering, Speech Retrieval systems are applications of Information Retrieval\",\n",
    "    \"Database Management system is used for storage\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 678,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 679,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['synthesis', 'information', 'system', 'database', 'management', 'digital', 'storage', 'speech', 'retrieval', 'filtering', 'applications', 'systems', 'used']\n"
     ]
    }
   ],
   "source": [
    "key = set()\n",
    "\n",
    "for i in doc1:\n",
    "    vocab_each = set(preprocessing(i))\n",
    "    for j in vocab_each:\n",
    "        key.add(j)\n",
    "key = list(key)\n",
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 680,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>synthesis</th>\n",
       "      <th>information</th>\n",
       "      <th>system</th>\n",
       "      <th>database</th>\n",
       "      <th>management</th>\n",
       "      <th>digital</th>\n",
       "      <th>storage</th>\n",
       "      <th>speech</th>\n",
       "      <th>retrieval</th>\n",
       "      <th>filtering</th>\n",
       "      <th>applications</th>\n",
       "      <th>systems</th>\n",
       "      <th>used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   synthesis  information  system  database  management  digital  storage  \\\n",
       "0          0            0       1         1           0        0        0   \n",
       "1          0            0       0         0           0        0        0   \n",
       "2          0            0       0         0           0        0        0   \n",
       "3          0            0       1         0           0        0        0   \n",
       "4          0            0       1         0           0        0        1   \n",
       "\n",
       "   speech  retrieval  filtering  applications  systems  used  \n",
       "0       0          0          0             0        1     1  \n",
       "1       0          0          0             0        0     0  \n",
       "2       0          0          0             0        0     1  \n",
       "3       0          0          0             1        1     0  \n",
       "4       0          0          0             0        0     1  "
      ]
     },
     "execution_count": 680,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boolean_table = dict()\n",
    "isthere1 = list()\n",
    "for i in key:\n",
    "    isthere = [0]*len(doc1)\n",
    "    for j in range(len(doc1)):\n",
    "        if i in doc1[j]:\n",
    "            isthere[j] = 1\n",
    "    isthere1.append(isthere)\n",
    "\n",
    "\n",
    "for i in range(len(key)):\n",
    "    boolean_table[key[i]] = isthere1[i]\n",
    "\n",
    "df = pd.DataFrame(boolean_table)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">a. Retrieve the documents for the Boolean query  “Information Retrieval Synthesis” using simple match. (Rank the documents in the order of relevance)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 681,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No match\n"
     ]
    }
   ],
   "source": [
    "query = \"Information Retrieval Synthesis\".lower().split()\n",
    "\n",
    "res = df[(df[query[0]] == 1) & (df[query[1]] & (df[query[2]]))]\n",
    "\n",
    "\n",
    "if(len(res) == 0):\n",
    "    print(\"No match\")\n",
    "else:\n",
    "    for i in list(res.index):\n",
    "        print(f\"Match found at Doc: {i}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">b.Retrieve the documents for the Boolean query  “Database Retrieval Storage” using weighted match. (Rank the documents in the order of relevance)</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 3, 2, 1, 0]"
      ]
     },
     "execution_count": 684,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isthere1 = list()\n",
    "query = \"Database Retrieval Storage\"\n",
    "query = preprocessing(query)\n",
    "\n",
    "doc1 = [\n",
    "    \"Information Retrieval Systems is used with database systems\",\n",
    "    \"Information is in Storage\",\n",
    "    \"Digital Speech can be used in Synthesis and Systems\",\n",
    "    \"Speech Filtering, Speech Retrieval systems are applications of Information Retrieval\",\n",
    "    \"Database Management system is used for storage\"\n",
    "]\n",
    "\n",
    "s = set(' '.join(doc1).split(\" \"))\n",
    "p = set(stopwords.words(\"english\"))\n",
    "l = []\n",
    "for i in s:\n",
    "    if i not in p:\n",
    "        l.append(i)\n",
    "\n",
    "d=dict()\n",
    "for i in range(len(doc1)):\n",
    "    for j in range(len(l)):\n",
    "        if i not in d.keys():\n",
    "            d[i] = [0] * len(l)\n",
    "        if l[j] in doc1[i]:\n",
    "            d[i][j] = 1\n",
    "\n",
    "query = \"Database Retrieval Storage\"\n",
    "p = [0] * len(l)\n",
    "q =query.split(\" \")\n",
    "for i in range(len(l)):\n",
    "    if l[i] in q:\n",
    "        p[i] = 1\n",
    "\n",
    "ans = []\n",
    "for i in d.keys():\n",
    "    m = []\n",
    "    for j in range(len(p)):\n",
    "        m.append(d[i][j] and p[j])\n",
    "    ans.append(m.count(l))\n",
    "\n",
    "import numpy as np\n",
    "t = np.array(ans)\n",
    "ans= list(t.argsort()[::-1])\n",
    "ans"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vector Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">iii.\tConstruct a vector space model to build the term weights. Compute the TF-IDF and identify the most important terms across the documents.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\jayde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\jayde\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import copy\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "nltk.download(\"punkt\")\n",
    "nltk.download('stopwords')\n",
    "docs=[\"Information Retrieval Systems is used with database systems\",\n",
    "\"Information is in Storage\",\n",
    "\"Digital Speech can be used in Synthesis and Systems\",\n",
    "\"Speech Filtering, Speech Retrieval systems are applications of Information Retrieval\",\n",
    "\"Database Management system is used for storage\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(doc,indx):\n",
    "    doc=doc.lower()\n",
    "    word_tokens = word_tokenize(doc)\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    l=list()\n",
    "    for i in range(0,len(word_tokens)):\n",
    "        if(word_tokens[i]==',' or word_tokens[i].lower() in stop_words or word_tokens[i].isnumeric()):\n",
    "            continue\n",
    "        else:\n",
    "            l.append(word_tokens[i].lower())\n",
    "    return (\" \").join(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,len(doc1)):\n",
    "    doc1[i]=preprocess(doc1[i],i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>information</th>\n",
       "      <th>retrieval</th>\n",
       "      <th>systems</th>\n",
       "      <th>used</th>\n",
       "      <th>database</th>\n",
       "      <th>storage</th>\n",
       "      <th>digital</th>\n",
       "      <th>speech</th>\n",
       "      <th>synthesis</th>\n",
       "      <th>filtering</th>\n",
       "      <th>applications</th>\n",
       "      <th>management</th>\n",
       "      <th>system</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.403755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.335153</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.403755</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.670306</td>\n",
       "      <td>0.335153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.638711</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.769447</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530899</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.428326</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.530899</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.355549</td>\n",
       "      <td>0.355549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.35127</td>\n",
       "      <td>0.235249</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.566804</td>\n",
       "      <td>0.566804</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.235249</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.416607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416607</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.516374</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.345822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   information  retrieval   systems     used  database   storage   digital  \\\n",
       "0      0.00000   0.403755  0.000000  0.00000  0.335153  0.000000  0.403755   \n",
       "1      0.00000   0.000000  0.000000  0.00000  0.638711  0.000000  0.000000   \n",
       "2      0.00000   0.000000  0.530899  0.00000  0.000000  0.000000  0.000000   \n",
       "3      0.35127   0.000000  0.000000  0.35127  0.235249  0.000000  0.566804   \n",
       "4      0.00000   0.416607  0.000000  0.00000  0.000000  0.516374  0.000000   \n",
       "\n",
       "     speech  synthesis  filtering  applications  management    system  \n",
       "0  0.000000   0.000000   0.000000      0.000000    0.670306  0.335153  \n",
       "1  0.000000   0.769447   0.000000      0.000000    0.000000  0.000000  \n",
       "2  0.428326   0.000000   0.530899      0.000000    0.355549  0.355549  \n",
       "3  0.566804   0.000000   0.000000      0.000000    0.235249  0.000000  \n",
       "4  0.000000   0.416607   0.000000      0.516374    0.000000  0.345822  "
      ]
     },
     "execution_count": 636,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "\n",
    "response = tfidf.fit_transform(doc1)\n",
    "tdidfTable = pd.DataFrame(response.toarray())\n",
    "\n",
    "tdidfTable.columns = [keys for keys in tfidf.vocabulary_.keys()]\n",
    "\n",
    "tdidfTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['applications',\n",
       " 'database',\n",
       " 'digital',\n",
       " 'filtering',\n",
       " 'information',\n",
       " 'management',\n",
       " 'retrieval',\n",
       " 'speech',\n",
       " 'storage',\n",
       " 'synthesis',\n",
       " 'system',\n",
       " 'systems',\n",
       " 'used']"
      ]
     },
     "execution_count": 637,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# identify the most important terms across the documents \n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "feature_names.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rank all the documents in the collection for the query “Speech Systems”?\n",
    "query = preprocessing(\"Speech Systems\")\n",
    "query = \" \".join(query)\n",
    "query_vector = tfidf.transform([query]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 0 4 1]\n",
      "speech filtering speech retrieval systems applications information retrieval\n",
      "digital speech used synthesis systems\n",
      "information retrieval systems used database systems\n",
      "database management system used storage\n",
      "information storage\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "doc1_vector = tfidf.transform(doc1)\n",
    "cosineSimilarity = cosine_similarity(doc1_vector, query_vector).flatten()\n",
    "\n",
    "print(cosineSimilarity.argsort()[:-10:-1])\n",
    "for i in cosineSimilarity.argsort()[:-10:-1]:\n",
    "    print(doc1[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">Compute the cosine similarities between docs 1 and docs 2 </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def cosine_similarity(x, y):\n",
    "    if len(x) != len(y):\n",
    "        return None\n",
    "    dot_product = np.dot(x,y)\n",
    "    mag_x = np.sqrt(np.sum(x**2))\n",
    "    mag_y = np.sqrt(np.sum(y**2))\n",
    "    np.sqrt(np.sum(x**2))\n",
    "    np.sqrt(np.sum(y**2))\n",
    "    cosine_similarity = dot_product / (mag_x * mag_y)\n",
    "    return cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.31622776601683794\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "Docs = [\n",
    "    \"Information Retrieval Systems is used with database systems\",\n",
    "    \"Information is in Storage\",\n",
    "    \"Digital Speech can be used in Synthesis and Systems\",\n",
    "    \"Speech Filtering, Speech Retrieval systems are applications of Information Retrieval\",\n",
    "    \"Database Management system is used for storage\"\n",
    "]\n",
    "\n",
    "x = CountVectorizer().fit_transform(Docs).toarray()\n",
    "\n",
    "\n",
    "cos_sim = cosine_similarity(x[0,: ], x[1,: ])\n",
    "\n",
    "print(cos_sim)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">Compute Dice Co-efficient between docs 3 and docs 4.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice(x, y):\n",
    "    x = x.astype(bool)\n",
    "    y = y.astype(bool)\n",
    "    sum_= x.sum() + y.sum()\n",
    "    if sum_== 0:\n",
    "        return 1\n",
    "    intersection= np.logical_and(x,y)\n",
    "    return 2. *intersection.sum()/ sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.23529411764705882"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = dice(x[2,: ], x[3,: ])\n",
    "d"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p align=\"center\">Compute the Jaccard co-efficient between docs 4 and docs 5.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jaccard(x, y):\n",
    "    intersection= np.logical_and(x,y)\n",
    "    union= np.logical_or(x,y)\n",
    "    similarity= intersection.sum()/ float(union.sum())\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 645,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "j = jaccard(x[3,: ], x[ 4,: ])\n",
    "j"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.7 (tags/v3.8.7:6503f05, Dec 21 2020, 17:59:51) [MSC v.1928 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "28e1b576861228abcf292d5aee661eb2e4c4972fc2d268dd66cc4c0717cd3198"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
